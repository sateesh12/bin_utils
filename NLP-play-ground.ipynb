{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Sateesh\n",
    "#Date. : 23/Aug/2020\n",
    "#Purpose: NLP play around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  spacy.lang.en import English\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the pipe names\n",
    "print(nlp.pipe_names)\n",
    "#tagger = Parts of speec tagger\n",
    "#parser = Dependency Parser\n",
    "#ner    = Named Entity recognizer\n",
    "#Also tokenizer is not considered as a part of pipe-line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the full pipe names\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a custom component which adds sums up the number of tokens in the doc object\n",
    "from spacy.lang.en import English\n",
    "import spacy\n",
    "nlp = English()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#Create a doc object for the purpose of testing\n",
    "\n",
    "def custom_component(doc):\n",
    "    doc_length = len(doc)\n",
    "    print('Lenght of the document is:', doc_length)\n",
    "    return doc #It is important to return the doc, else all hell breaks loose !\n",
    "\n",
    "\n",
    "#Print pipeline before adding, when the doc is processed the number of tokens is not printed\n",
    "print('B4')\n",
    "doc1 = nlp('My name is sateesh')\n",
    "print(nlp.pipeline)\n",
    "\n",
    "#Now add the custom component to the standard pipeline at the start\n",
    "nlp.add_pipe(custom_component, first=True)\n",
    "\n",
    "#Print the pipeline after adding, now for every new nlp object the number of tokens is printed\n",
    "print('After')\n",
    "doc2 = nlp('My name is Sateesh')\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x7ff71a55fdd0>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7ff70a0fbd00>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7ff70a0fbc20>), ('animal_detector', <function animal_detector at 0x7ff719225200>)]\n",
      "Golden Retriever\n",
      "[('Golden Retriever', 'ANIMAL')]\n"
     ]
    }
   ],
   "source": [
    "#Write a custom component which identifies all animal names\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "\n",
    "#Create a new component which can identify animal names\n",
    "def animal_detector(doc):\n",
    "    #Create a pattern matcher\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"DOG\", None, [{\"LOWER\": \"golden\"}, {\"LOWER\": \"retriever\"}])\n",
    "    matches = matcher(doc)\n",
    "    for match_id,start,end in matches:\n",
    "        span = doc[start:end]\n",
    "        print(span.text)\n",
    "        spans = [Span(doc, start, end, label=\"ANIMAL\")]\n",
    "        doc.ents = spans\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(animal_detector,after='ner')\n",
    "print(nlp.pipeline)\n",
    "\n",
    "doc = nlp('African Buffalo Albatross Alligator Alpaca American Bison Ant Antelope Ape Golden Retriever')\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My False\n",
      "name False\n",
      "is False\n",
      "kalidas True\n"
     ]
    }
   ],
   "source": [
    "#Add a color attribute to the token\n",
    "#In the below example for the doc[3] color attribute is made true. This has nothing to do with color of printing , \n",
    "#it is all about making that custom attribute to be true.\n",
    "\n",
    "from spacy.tokens import Doc, Token, span\n",
    "from spacy.lang.en import English\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "Token.set_extension('is_color',default=False,force=True)\n",
    "doc = nlp(\"My name is kalidas\")\n",
    "doc[3]._.is_color = True\n",
    "for token in doc:\n",
    "    print(token.text, token._.is_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reverse I\n",
      "reverse ma\n",
      "reverse gniog\n",
      "reverse ot\n",
      "reverse eb\n",
      "reverse desrever\n",
      "reverse gnisu\n",
      "reverse na\n",
      "reverse etubirrtta\n"
     ]
    }
   ],
   "source": [
    "#Add an attribute whihc can also be a function call\n",
    "#Not sure what is the use case for this, especially considering that in the pipe-line itself we can add\n",
    "#additional functions, maybe this works only on certain doc objects.\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Token\n",
    "import spacy\n",
    "\n",
    "doc = nlp('I am going to be reversed using an attrribute')\n",
    "\n",
    "def get_reverse(token):\n",
    "    return token.text[::-1]\n",
    "    \n",
    "#Print current set of existing attributes\n",
    "#To-Do figure out how to print current attributes\n",
    "\n",
    "#Add a method extension\n",
    "Token.set_extension('reversed',getter=get_reverse)\n",
    "\n",
    "#Now call to the method extension\n",
    "for token in doc:\n",
    "    print('reverse', token._.reversed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>I am</b>\n"
     ]
    }
   ],
   "source": [
    "#Here is a piece of code whihc adds html tag to the doc which has been sent to it\n",
    "#using the method attribute\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Span\n",
    "\n",
    "#Method extension definition\n",
    "def to_html(span,tag):\n",
    "    return f\"<{tag}>{span.text}</{tag}>\"\n",
    "\n",
    "#Decleration of the method extension\n",
    "Span.set_extension(\"to_html\",method=to_html,force=True)\n",
    "doc = nlp(\"I am a long sentence\")\n",
    "span = doc[0:2]\n",
    "\n",
    "#Calling the method extension\n",
    "print(span._.to_html(\"b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return an wiki link for the entity types."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
